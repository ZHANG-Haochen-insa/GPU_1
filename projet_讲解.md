# Projet PDF 中文讲解

## 作者：Emmanuel Quémener - INSA 2023

---

## 第1页：标题页

**主题：从并行架构到并行程序 - 从度量学到性能测量**

这是一个关于并行计算的课程演讲。标题中引用了布鲁克斯定律（Brooks法则）：
> "不要让9个女人在1个月内完成一个女人9个月才能完成的事情..."

这个比喻说明了并行化不是简单地增加人力就能按比例加速任务完成。

---

## 第2页：物理学家的视角

**演讲者的背景和方法论：**

- **"系统"方法**：继承自模拟计算机的思维方式
  - 将计算机系统看作整体：网络/硬件/操作系统/库/代码/使用等

- **"圣托马斯"方法**（Saint Thomas - 眼见为实）
  - 通过实际测量进行归纳学习

- **"试飞员"方法**
  - 表征系统，寻求最优利用方式

---

## 第3页：演讲的注意事项

**这个演讲不会涉及的内容：**

1. **不是并行计算的通用介绍**
   - 相关课程由Lyon Calcul组织
   - 参考：https://computing.llnl.gov/tutorials/parallel_comp/

2. **不是并行化语言的介绍**
   - MPI：https://computing.llnl.gov/tutorials/mpi/
   - Posix Threads：https://computing.llnl.gov/tutorials/pthreads/
   - OpenMP：https://computing.llnl.gov/tutorials/openMP/
   - 作者说这些是他学习的地方

**演讲的重点：**
- 分享那些从未（或很少）被讲述的内容

---

## 第4页：中心Blaise Pascal的理念

**一个说明性的例子 - NASA X-29实验飞机：**

- 机身来自F-5战斗机
- 发动机来自F-18
- 起落架来自F-16

**研究内容：**
- "鸭翼"设计
- 迎角超过50°
- "线传飞行"（Fly-By-Wire）技术

**理念：回收利用、重复使用、探索新领域**

这个比喻说明了作者的方法：利用现有的工具和方法，组合创新来探索新的可能性。

---

## 第5页：目标 - 从飞行包线到并行包线

**从飞行性能曲线到并行性能曲线**

展示了不同并行化方法的性能对比：
- Pthreads
- OpenMP
- MPI
- OpenCL Intel
- OpenCL AMD
- 理论值

还展示了宇宙学代码PKDGRAV3在不同条件下的表现。

**核心理念：**就像测试飞机的飞行包线（速度、高度的性能边界），我们也要测试并行代码在不同条件下的性能边界。

---

## 第6页：从科学方法到数值实验

展示了科学方法的六个步骤：
1. 进行观察
2. 形成假设
3. 执行实验
4. 分析数据
5. 报告发现
6. 邀请他人重现结果

这个方法论同样适用于数值实验和并行计算的研究。

---

## 第7页：一些定义和缩写

**重要术语：**

- **ALU**：算术逻辑单元
- **CPU**：中央处理单元
- **Flops**：每秒浮点运算次数
- **(GP)GPU**：(通用)图形处理单元
- **MPI**：消息传递接口
- **RAM**：随机存取存储器
- **SMP**：共享内存处理器
- **TDP**：热设计功耗

**作者自定义的术语：**
- **PR**：并行率（MPI中的进程数，OpenMP中的线程数，GPU中的块/工作项）
- **Itops**：每秒迭代操作数
- **QPU**：量子处理单元（并行率=1时执行的程序）
- **EPU**：等效处理单元（从并行程序的最佳执行推导出的并行率）

---

## 第8页：物理工作或智力工作 - 发动机与计算机

**作为"功率"辅助工具**

展示了从古代到现代的演变：

**物理工具的演变：**
- 古埃及的牛耕
- 中世纪水车
- 蒸汽机
- 现代发动机

**计算工具的演变：**
- 安提基特拉机械（公元前87年）
- 布莱兹·帕斯卡的计算器（1642年）
- 图灵的计算机（1943年）
- 现代CPU

两者都是人类能力的延伸工具。

---

## 第9页：计算机是织布机吗？

**冯·诺依曼架构**

展示了计算机的基本组成：
- **中央处理单元（CPU）**
  - 控制单元
  - 算术/逻辑单元
- **存储单元**
- **输入设备**
- **输出设备**

右图展示了实际的织布机，暗示计算机的工作原理类似于自动织布机 - 都是按照预设的"程序"（织布机的打孔卡片）来执行重复性任务。

---

## 第10页：冯·诺依曼架构 - Intel 50年的演变

展示了从Intel 4004到Intel Skylake的演变：

**Intel 4004（1971）：**
- 简单的架构
- 基本的ALU和控制单元

**Intel Skylake核心（现代）：**
- 极其复杂的结构
- 多级缓存（L1i、L1d、L2、L3）
- 前端、执行引擎、内存子系统
- 大量的输入/输出单元

**关键观察：**基本的冯·诺依曼架构保持不变，但复杂度增加了数千倍。

---

## 第11页：信息革命 - IBM个人计算机（PC）

**1981年的IBM PC**

展示了IBM PC的主板，标注了：
- 中央处理单元（黄色）
- 存储单元（粉色）
- 输入设备
- 输出设备
- 算术/逻辑单元

这是个人计算机时代的开端，使计算机从大型机走向个人。

---

## 第12页：主板演变 - 从1989到2002年

展示了6块主板的演变：
- **80386SX**（1989）
- **80486SX**
- **80486DX4**
- **Amd5x86**
- **K6-2**
- **K7**

**可见变化：**
- 集成度不断提高
- 组件密度增加
- CPU和内存（标注的红色、黄色、绿色区域）的集成越来越紧密

---

## 第13页：主板演变 - 从2005到2018年

**更现代的演变：**
- **Athlon64 X2**（2005）- 双核时代
- **Threadripper 1950X**（2018）- 16核32线程

**重大变化：**
- 散热系统变得极其重要（可见大型散热器和风扇）
- 多核心成为标准
- 功耗管理成为关键问题

---

## 第14页：Socket内部 - 3个四核处理器的例子

展示了三种不同的四核处理器架构：

**Intel Sandy Bridge：**
- 集成处理器图形
- 4个核心
- 共享的L3缓存
- 统一的调度器

**Intel Nehalem：**
- 更传统的布局
- 4个核心
- 共享L3缓存

**AMD Bulldozer：**
- 独特的"推土机"架构
- 模块化设计
- 共享的浮点调度器和整数调度器

每种架构都有不同的权衡和优化策略。

---

## 第15页：但现在每个核心都是噩梦...

**Nehalem和Skylake核心的详细架构**

展示了单个处理器核心内部的极度复杂性：

**包含的功能单元：**
- 指令获取和预解码
- 分支预测器
- 指令缓存
- 解码器
- 重命名/分配
- 保留站
- 执行单元（多个ALU）
- 加载/存储单元
- 数据缓存

一个现代CPU核心内部的复杂度堪比早期的整个处理器！

---

## 第16页：但这都是关于PC的... Top 500与时俱进

**从1993年至今的超级计算机分类：**

**架构类别：**
- **单处理器**（Single Processor）
- **SMP**：对称多处理器
- **SIMD**：单指令多数据
- **MPP**：大规模并行处理器
- **Constellation**：星座架构（核心数>>节点数）
- **Cluster**：集群（使用"通用"机器）

**观察：**有4种架构类型已经"消失"了，现在几乎都是集群架构。

---

## 第17页：计算机中的"定律" - 摩尔定律及其演变

**摩尔定律的三个版本：**

1. **1965年**：晶体管的"复杂度"每年翻倍
2. **1975年**：处理器上的晶体管数量每2年翻倍
3. **当前版本**：每18个月"性能"翻倍

**两张图表：**
- 左图：晶体管数量随时间的增长（指数增长）
- 右图：Top 500超级计算机性能的增长

---

## 第18页：阿姆达尔定律及其局限性

**阿姆达尔定律公式：**
- T = T₁(s + p/n)
  - T和T₁：n个处理器和1个处理器的执行时间
  - s和p：代码的串行和并行部分百分比
  - n：处理单元数量

- **加速比 = T₁/T = 1/(1-p+p/n)**

**性能表格示例：**

| 并行率 | N=500 | N=1000 |
|--------|-------|--------|
| 90%    | 9.8倍(2%效率) | 9.9倍(1%效率) |
| 99%    | 83倍(17%效率) | 91倍(9%效率) |
| 99.9%  | 334倍(66%效率) | 500倍(50%效率) |
| 99.99% | 476倍(95%效率) | 909倍(91%效率) |

**关键启示：**即使99%的代码可以并行化，在500个核心上也只能达到17%的效率！

---

## 第19页：代码与性能 - 选择什么定义？

**词源学（Etymonline）：**

**Code（代码）**：来自拉丁语codex"书籍，法律书"
- "系统化的法律汇编"（1236年）
- "电报通信系统"（1866年）

**Performance（性能）**：
- "某事的完成"
- 约1590年："已完成的事情"
- 1929年："系统最优特性的集合"

**Benchmark（基准测试）**：
- 来自"bench-mark"，"测量的参考点"（1838年）
- 自1884年起的比喻意义："作为评估或比较基础的标准化问题或测试"

**作者的选择：**
- Code：两个含义都用
- Performance：三个含义都用
- Benchmark：使用比喻意义

---

## 第20页：代码是什么？实验协议！

**在厨房里：**
- 我们有食材，但我们想要一道菜！

**在科学领域，有3种形式：**

1. **模拟（Simulation）**："为理论服务（谨慎地？）"
2. **处理（Traitement）**：给"苛刻的"实验者使用
3. **可视化（Visualisation）**：看到（事物）以感知（它们的相互作用）（也可以分享！）

**每次执行都是一次实验（而且是唯一的！）：**
- **食谱**：成为"进程"的"代码"
- **工具**：库、操作系统、硬件、网络等
- **食材**：建模、数据
- **执行**：一次实验不能简化为其结果！

---

## 第21页：如果计算是烹饪... 代码只是食谱

**对应关系：**

| 计算概念 | 烹饪类比 |
|----------|----------|
| 代码 | 食谱 |
| 计算机 | 厨房 |
| 输入数据 | 食材 |
| 输出数据 | 烹饪的菜肴 |
| 进程 | 烹饪过程 |
| 控制单元 | 厨师 |
| ALU | 厨具 |
| 动态RAM | 橱柜、桌子等 |
| L3缓存 | 整个工作台 |
| L2缓存 | 一步之内的工作台 |
| L1缓存 | 工作台、容器 |
| 寄存器 | 厨师的手 |
| 我 | 顾客 |
| 批处理请求 | 订单 |

---

## 第22页：程序家族

**如何区分我使用的不同代码？**

1. **"我引以为豪的我的代码！"**

2. **老板的代码**
   - 或者更确切地说，是连续几代学生的分层产物

3. **"专业"代码**
   - **宜家模式**：带有编译说明分发
   - **Crozatier模式**：即用型

**每个家族的遗产问题！**

**依赖关系：**
- 通用库：BLAS、Lapack、FFTw
- 专有库：Mathworks、Intel、Nvidia、AMD等
- 硬件！

---

## 第23页：性能：如何？目标问题！

**比喻：你需要什么样的车？**

- 把所有行李和家人装进车里
- 在夜店出来时吸引女孩的注意
- 在拥堵的城市中从A点到B点
- 在美国爬派克斯峰

展示了四种不同的交通工具：
- 自行车
- 拉力赛车
- 家用旅行车
- 改装跑车

**关键思想：**性能取决于你的目标，没有"通用最佳"解决方案。

---

## 第24页：性能：如何？可观测量的问题

**体育运动中的性能：**

展示了不同运动员的例子：
- 跑100米？
- 跑马拉松？
- 掷铅球？
- 完成七项全能？

每种运动需要不同的训练和优化策略。同样，不同的计算任务需要不同的优化方法。

---

## 第25页：性能：由目标决定

**关键性能指标：**

- **速度（Vitesse）**：更准确说是频率，1/(经过的时间)或Wall Clock时间
- **工作量（Travail）**：在一段时间内占用资源
- **效率（Efficacité）**：资源的最优利用
- **可扩展性（Scalabilité）**：扩展到更大规模的能力
- **可移植性（Portabilité）**：集成到其他IT基础设施的能力
- **可维护性（Maintenabilité）**：维护系统所花费的人力时间

**一般方法：**
- 定义标准
- 在一组相关测试中寻找极值

---

## 第26页：速度作为标准 - "Speed, I'm Speed..."

**所有持续时间，不仅仅是执行时间**

**使用代码时的3个成本（时间）：**

1. **进入成本**：学习使用、集成到基础设施等
2. **运营成本**：维护、使用
3. **退出成本**：用等效代码或技术替换

**优化（及其偏见）：DD/DE > 1是否相关？**
- DE：所有执行的总持续时间（执行持续时间）
- DD：尝试最小化执行持续时间所花费的时间（开发持续时间）

**估算这些值：**
- 系统工具、语言、代码、硬件中的度量工具等

**"我之后？洪水？"**：代码的未来如何？

---

## 第27页：工作量作为性能标准

**工作量："时间就是金钱"**

**资源：**CPU、RAM、GPU、存储、网络等

**事实上是套娃：**
- CPU：多个核心、CU、ALU、堆栈等
- RAM/SRAM：4个级别
- 存储：本地、慢速共享(NFS)、快速共享(GlusterFS、Lustre等)
- 网络：慢速(千兆)、快速低延迟(InfiniBand、Omnipath)

**Job：资源的预订（和占用）**
- 传统上，在批处理系统中：Slots × Wall Clock

**对于代码，系统足迹是什么？**
- 分析工具、系统工具

---

## 第28页：可扩展性作为标准

**可扩展性：**
- 在要完成的任务中：经过时间？f(经过时间)
- 在要动员的资源中：g(系统资源)

**要避免的陷阱：**
- 规模效应（实际上，阈值效应更糟）
- 需要指挥家吗？从四重奏到交响乐团...
- 无论程序如何，机器资源都是有限的...

**你真的认为这让我笑吗？:-/**

**并行化不可避免，但为什么？**

---

## 第29页：专业代码与硬件 - 可扩展性示例

展示了几个科学计算代码的可扩展性测试结果：

- **CP2K**：化学/材料科学代码
- **Lammps**：分子动力学模拟
- **VASP**：第一性原理计算
- **PKDGRAV3**：宇宙学N体模拟

以及在不同GPU上的Pi蒙特卡罗测试：
- Vega 64
- Radeon VII
- GTX 1080 Ti
- RTX 2080 Ti
- Tesla P100
- Threadripper 1950X

每个代码在不同硬件和并行度下都有不同的性能曲线。

---

## 第30页：计算机性能 - 在Linpack和Phoronix之间

**Linpack：**
- 显示处理器性能
- 显示处理器和核心大小的性能热图

**Phoronix：**
- 编译器性能（GCC 6.3.0）
- 系统和操作系统版本
- 驱动程序版本

**关键点：**性能不仅取决于硬件，还取决于整个软件栈。

---

## 第31页：计算机性能 - Linpack与Top 500

**什么：**地球上500台最强大的超级计算机

**何时：**每年两次，6月和11月

**哪里：**全世界

**谁（编写代码）：**田纳西大学ICL

**如何：**FP64的高性能LinPack，LU分解求解系统

**多少钱：**开源，依赖BLAS：https://www.netlib.org/benchmark/hpl/

**为什么：**国家之间"展示肌肉"（战略问题）...

展示了国家份额饼图和LU分解的矩阵划分示意图。

---

## 第32页：Linpack与Top 500 - 尊重摩尔定律。如何？

**打破"热墙"的2条途径：**
- 从多核到众核
- 使用大量ALU的加速器

图表显示：
- 20年内性能提升1000倍，然后停止（或下降）
- 处理器频率扩展随时间的变化，显示频率在2005年后基本停滞

**关键观察：**单核频率无法继续提升，必须走并行化路线。

---

## 第33页：计算机中的能量 - 物理学家的视角

**电子学与热学**

展示了Intel Pentium 4处理器和电磁炉的图片。

**核心信息：**
- 现代处理器的热密度类似于电磁炉！
- 功耗和散热成为限制性能提升的关键因素

这就是为什么需要并行化 - 通过增加核心数量而不是提高频率来获得更多性能。

---

## 第34页：为什么并行化（是不可避免的）？TDP的约束

**频率的兴衰：**
- 1981-1999年：从4 MHz到400 MHz，约20年增长100倍
- 1999-2004年：从400 MHz到3 GHz，5年增长约10倍
- 2004-2009年：从3 GHz降至2 GHz

**热设计功耗（TDP）：**最大散热包络

**TDP = ½CV²f**
- C = 电容，f = 频率，V = 供电电压（是f的函数！）

**处理器的TDP：**150W（在4cm²上）
- 电磁炉的热密度！

**TDP成为性能的限制因素**

电容 = 工艺精度² × 晶体管数 × Mylq常数（≈0.015）

**可行解决方案：增加处理单元（PU）数量**

---

## 第35页：科学计算中的能量 - 物理学家的观点

**力学类比：**

显示了功（Work）、力（Force）、距离（Distance）、功率（Power）和时间（Time）之间的关系。

**公式：**
W = ∫F dx = ∫P dt

**"引擎"表征的功率定义为以下的乘积：**
- 频率
- 单元数量
- 单位功率

这个类比帮助我们理解计算系统的"引擎"特性。

---

## 第36页：很久以前，1985到2005年间 - 变量是频率！

展示了：
- **马力vs RPM**的摩托车性能曲线（5种不同摩托车）
- **处理器频率随时间的变化**（1985-2015）

**关键观察：**
- 就像发动机，频率（RPM）曾经是提升性能的主要方式
- 2005年后，频率增长基本停滞
- 必须寻找其他方法来提升性能

---

## 第37页：工作量与IT资源 - 引擎作为动力源

**可扩展性 vs 并行度**

显示了马力vs RPM的曲线和Pi蒙特卡罗代码在不同并行化方法下的性能：
- Pthreads
- OpenMP
- MPI
- OpenCL Intel
- OpenCL AMD
- 理论值

**关键问题：**
- 这些"引擎"在负载下的行为如何？
- "引擎"是一个包含硬件、操作系统和软件的"系统"

---

## 第38页：厨房之外 - 搬家

**目标：**将420个纸箱从A地搬到B地

**手段：**
- 6个人，每人可以搬1个纸箱
- 2辆手推车，每辆可装6个纸箱
- 每边有一部电梯，可容纳12个纸箱
- 一辆面包车，可装100个纸箱

**如何组织搬家？**
- 哪些是并行单元，它们的性质是什么？
- 在哪里找到Flynn分类法的元素？

这个例子说明了不同层次的并行化。

---

## 第39页：从处理单元的角度

**俄罗斯套娃式的层次结构：**

从最大到最小：
- **集群（Cluster）或机群**
- **节点（Node）**
- **插槽（Socket）**
- **核心（Core）**
- **ALU**

就像俄罗斯套娃一样，每一层都包含下一层，形成层次化的并行结构。

---

## 第40页：分层存储器！

**没有共享内存...因此需要通信！**

展示了存储器层次结构：

| 层次 | 大小 | 带宽 |
|------|------|------|
| **集群** - DRAM | 20 TB | 7 GB/s |
| **节点** - DRAM | 64 GB | 20 GB/s |
| **Socket** - L3 | 20 MB | 120 GB/s |
| **核心** - L2/L1 | 256 KB | 200 GB/s |
| **ALU** - 寄存器 | 512 bit | 333 GB/s |

**通过消息传递、共享文件进行通信...**

每向上一层，容量增加但速度大幅下降。这是并行编程的关键挑战之一。

---

## 第41页：如果计算是烹饪... 关于内存

**对应关系扩展到内存层次：**

- **代码** ~ 食谱
- **计算机** ~ 厨房
- **输入数据** ~ 食材
- **输出数据** ~ 烹饪的菜肴
- **进程** ~ 准备过程
- **控制单元** ~ 厨师
- **ALU** ~ 厨具
- **动态RAM** ~ 橱柜、桌子等
- **L3缓存** ~ 整个工作台
- **L2缓存** ~ 一步之内的工作台
- **L1缓存** ~ 工作台、容器
- **寄存器** ~ 厨师的手

图片展示了动漫中的厨房场景，标注了不同的内存层次。

---

## 第42页：如何并行编程？编程模型

**并行编程的高级库：**

| 技术 | 集群 | CPU节点 | GPU节点 | Nvidia节点 | 加速器 |
|------|------|---------|---------|------------|--------|
| MPI | 是 | 是 | 否 | 否 | 是* |
| PVM | 是 | 是 | 否 | 否 | 是* |
| OpenMP | 否 | 是 | 否 | 否 | 是* |
| Pthreads | 否 | 是 | 否 | 否 | 是* |
| **OpenCL** | 否 | 是 | 是 | 是 | 是 |
| CUDA | 否 | 否 | 否 | 是 | 否 |
| TBB | 否 | 是 | 否 | 否 | 是* |
| OpenACC | 否 | 是 | 否 | 是 | 是 |
| Kokkos | 否 | 是 | 否 | 是 | 是 |
| SyCL | 否 | 是 | 是 | 是 | 是 |

**高级数学库：**

| 库 | 集群 | CPU节点 | GPU节点 | Nvidia节点 | 加速器 |
|----|------|---------|---------|------------|--------|
| BLAS | BLACS/MKL | OpenBLAS/MKL | clBLAS | CuBLAS | OpenBLAS/MKL |
| LAPACK | Scalapack/MKL | Atlas/MKL | clMAGMA | MAGMA | MagmaMIC |
| FFT | FFTw3 | FFTw3 | clFFT | CuFFT | FFTw3 |

OpenCL的通用性最强！

---

## 第43页：你的科学计算"驾驶执照"？

**在法国应用数学书中的一段话：**
> "物理学家对数学的使用，数学家很容易将其等同于无意识！"

**作为IT资源的BOFH（Bastard Operator From Hell）：**
> "科学家对IT资源的典型使用，我很容易将其等同于不一致！"

**你"驾驭"你的使用了吗？**

展示了两张监控工具的截图：
- **htop**：进程和CPU使用监控
- **dstat**：系统资源统计

---

## 第44页：阿姆达尔定律？真相还是谎言？准备服下"红色药丸"？

展示了多张实际测量的性能图表，显示了与阿姆达尔定律的偏差：

- Pi蒙特卡罗代码的加速比测量
- 不同代码在不同并行度下的表现
- Lammps在不同GPU和CPU配置下的性能

还有电影《黑客帝国》中Neo选择红色药丸的场景。

**暗示：**现实比阿姆达尔定律复杂得多！

---

## 第45页：计算机中的可观测量

**Observable = function(代码, 数据, 后台)**

**我掌控什么？**

- **代码？**
  - 所有代码？
- **数据？**
  - 数据访问
- **后台：**
  - 网络？系统？

**一个常量：观测会干扰...**
- **代码外**：time等，但也包括其他
- **代码内**：带计时器的系统命令

---

## 第46页：autant d'"Instructions par Cycle"！怎么可能？

**CPU内部的古老而深刻的演变：**

1. **RISC取代CISC**：
   - RISC：每周期1条指令

2. **"流水线"成为"规则"**：
   - 5个操作"似乎"在1个周期内执行

3. **浮点单元（FPU）集成到CPU中**
   - 这是专用的ALU

4. **CPU中集成多个专用ALU**
   - 从AMD K6的5个到Zen架构每核心的10个

5. **每个ALU集成矢量化**：
   - 最初用于3D操作（MMX、3DNow、SSE、SSE2...AVX512）

6. **Socket集成多个核心**（UC+ALUs+缓存内存）

展示了流水线阶段表，显示如何在5个周期内同时执行5条指令的不同阶段。

---

## 第47页：Top 500 - 摩尔定律得到尊重。如何？

**两张图表：**

1. **核心数/Socket - 系统份额**
   - 显示从多核到众核的转变
   - 2007年的相变

2. **加速器/协处理器 - 系统份额**
   - 自2005年起的加速器
   - 不仅仅是(GP)GPU和Phi

**关键：**
- 多核+加速器是保持摩尔定律的方式
- 纯粹的频率增长已经停止

---

## 第48页：为什么不使用LinPack？自己测试...这是欺骗...

**太多"自由"参数（从未公布）**

**构造商的太多"欺骗"：**
- HPL和HPCC：约15%的效率
- Linpack Intel MKL：57%到92%的效率
- Nvidia的CUDA：约20%的效率（编译起来是噩梦）
- 他们如何在数百万核心上达到75%的效率？

**太多"位"：**只有64位，对应用来说太多了

**因此在其他地方寻找，更简单、更通用的方法**

---

## 第49页：什么是并行化？回到源头

**词源学（etymonline.com）：**在另一个旁边

- 来自para-"旁边"
- 来自allelois"每个"，来自allos"其他"

**并行化：**要完成的任务，有限的资源

- 并行执行不同的任务
- 在多个资源上执行一个任务
  - 稀疏通信：粗粒度
  - 频繁通信：细粒度

**并行化的悖论，像经线！**

展示了地球经线的图示。

---

## 第50页：并行化要多少钱？时间、硅、复杂度...

**3个时间成本：**
- 进入成本、运营成本、退出成本
- 执行时间与适配时间的比较

**硅：**技术成本差异很大
- SMP（共享内存处理器）：昂贵且有限
- MPP（大规模并行处理）：对非常特定的网络要求高
- 集群易于扩展

**复杂度：**大量逻辑门的必然结果
- GPU"核心"（QPU）比CPU核心简单
- GPU"核心"（QPU）比CPU核心慢多达50倍

---

## 第51页：如何思考并行化 - "问题在于粒度..."

**4种情况：**
- **1个输入 / 1个进程？**优化进程！
- **1个输入 / Y个进程？**优化每个进程！
- **X个输入 / 1个进程？**优化分发！
- **X个输入 / Y个进程？**两者都优化！

**粒度由通信率定义！**

- **细粒度：**频繁通信（约>>1/秒）
- **粗粒度：**稀疏通信（约<1/秒）
- **"令人尴尬的并行"：**独立任务

---

## 第52页：如何思考并行化 - Flynn分类法

**SISD：**单指令单数据

**SIMD：**单指令多数据
- 矢量化

**MISD：**多指令单数据
- 流水线

**MIMD：**多指令多数据

**让我们在"厨房门后"看一眼（在硅中）？**

展示了对应的图片：单个厨师、工厂流水线、多个厨师。

---

## 第53页：如何利用并行化？并行执行策略...

**细粒度流水线，在硅上：**
- 同时进行5个简单指令：
  1. 指令获取
  2. 指令解码
  3. 执行
  4. （如有必要）内存访问
  5. 写入结果
- RISC的2个规范：每周期1条指令，使用寄存器

**2种不同方法：**
- **矢量化：**汇编/处理/分离
- **分发：**分发/处理/收集

**实际上是中值化 ;-)**

展示了分离和组装、分发和收集的示意图。

---

## 第54页：超越厨房 - 搬家

这页重复了第38页的内容，关于将420个纸箱从A地搬到B地的例子，强调不同层次的并行化。

---

## 第55页：从处理单元的角度

重复了第39页的俄罗斯套娃层次结构图，显示从集群到ALU的各个层次。

---

## 第56页：分层存储器！

重复了第40页的内容，展示了从集群的20TB/7GB/s到ALU寄存器的512bit/333GB/s的存储器层次结构。

---

## 第57页：如果计算是烹饪... 关于内存...

重复了第41页的内容，展示了存储器层次与厨房类比，以及动漫厨房场景中标注的L1、L2、L3和RAM。

---

## 第58页：如何并行编程？编程模型

重复了第42页的内容，展示了各种并行编程模型和库在不同硬件上的支持情况。

---

## 第59页：编程模型（续）

继续显示并行编程的高级数学库支持表。

---

## 第60页：你的科学计算"驾驶执照"？

重复了第43页的内容，展示htop和dstat监控工具。

---

## 第61页至第98页：黑洞光线追踪项目

**从第61页开始，演讲进入了一个具体的案例研究：**

这是关于黑洞周围吸积盘的光线追踪模拟项目：

**第61-70页：物理和数学基础**
- 基于JP Luminet 1979年的论文
- Einstein广义相对论
- Schwarzschild度规
- 极坐标方程
- 二阶微分方程系统

**第71-75页：实现方法**
- 光线追踪（Ray Tracing）方法
- 从观察者的眼睛反向追踪光线
- 计算光子轨迹
- 两种物理模型：单色和黑体辐射

**第76-80页：代码实现**
- 两种方法：
  1. 系统性方法（每像素）
  2. 经济方法（利用圆柱对称性）
- C语言实现
- 主循环遍历impact参数和角度

**第81-88页：性能测试**
- 在16个CPU上测试（从1989年的80386SX到2018年的Threadripper）
- 5次技术革命：
  1. FPU集成
  2. RISC架构
  3. 矢量化单元
  4. 多核心
  5. GPU加速

**第89-97页：并行化**
- OpenMP实现：17-18倍加速
- OpenCL实现：多种方法
  - EachCircle
  - EachPixel
  - TrajectoPixel
  - TrajectoCircle
- OpenCL在某些CPU上表现优异

**第98页：结论**
- **摩尔定律*得到尊重！终于...**
- 通过并行化，性能每18个月翻倍！
- 显示了从1990年到2020年的性能增长图

---

## 总结

这是一个关于并行计算性能测量的深入演讲，通过以下方式展开：

1. **理论基础：**摩尔定律、阿姆达尔定律、Flynn分类法
2. **实践方法：**使用厨房、搬家等类比解释并行计算
3. **具体案例：**黑洞光线追踪项目
4. **性能测试：**30年计算机硬件演变的系统测试
5. **结论：**通过并行化确实可以维持性能的指数增长

**核心信息：**
- 单核频率已达极限
- 并行化是性能提升的唯一途径
- 需要针对不同硬件和应用选择合适的并行化策略
- 实际测量比理论预测更重要
